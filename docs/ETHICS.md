# Ethics, Fairness, and Responsible Use

This document addresses the ethical considerations for the BLUFF benchmark, following KDD's requirements for responsible dataset development.

---

## Data Privacy and Consent

**No personally identifiable information (PII).** BLUFF contains no private user data, personal communications, or information about private individuals. All human-written text (HWT) is sourced exclusively from professionally published fact-checking articles intended for public consumption by IFCN-certified organizations and CredCatalog-indexed publishers.

**No consent requirements.** Because all source data is publicly published professional journalism, individual consent is not applicable. Source organizations are credited in the dataset metadata.

---

## Bias Awareness and Mitigation

### Known Biases

1. **Geographic bias.** HWT data coverage correlates with the global distribution of fact-checking infrastructure. Regions with fewer fact-checking organizations (Sub-Saharan Africa, Central Asia, Pacific Islands) have less representation. We partially mitigate this through LLM-generated content that extends coverage to 78 languages.

2. **Topical bias.** Fact-checked content skews toward politically salient topics (elections, public health, government policy). This reflects the priorities of fact-checking organizations rather than the full spectrum of disinformation.

3. **Generation quality bias.** LLM-generated content for big-head languages is likely higher quality than for long-tail languages, reflecting the training data distribution of frontier models. We document and measure this disparity through our benchmark results (9.0–25.3% cross-lingual performance gaps).

4. **Temporal bias.** The dataset reflects disinformation patterns at the time of collection and may not capture emerging techniques or evolving narratives.

### Mitigation Strategies

- Explicit documentation of coverage gaps and known limitations
- Separate evaluation metrics for big-head vs. long-tail languages to surface disparities
- mPURIFY quality filtering with asymmetric thresholds to maintain quality standards
- Linguistically-informed training strategies that demonstrably reduce performance gaps
- Open contribution model to expand language coverage over time

---

## Potential for Misuse

### Risks

BLUFF contains realistic synthetic disinformation generated by frontier LLMs. The primary misuse risks include:

1. **Disinformation generation.** The AXL-CoI framework and manipulation tactics could theoretically be adapted to generate disinformation at scale.
2. **Detection evasion.** Understanding detection model weaknesses (documented in our results) could inform adversarial attacks.
3. **Amplifying existing biases.** Models trained on BLUFF could inherit biases present in the data.

### Safeguards

1. **Research-only license.** The dataset is released under CC BY-NC-SA 4.0, restricting commercial use and requiring attribution.
2. **Metadata watermarking.** All synthetic content includes metadata identifying it as research material.
3. **Detection models co-released.** Baseline detection models are released alongside the data to ensure defensive capabilities keep pace.
4. **Framework abstraction.** The AXL-CoI code provides the architectural framework without the specific adversarial prompts needed for production-scale generation.
5. **Responsible disclosure.** We follow responsible disclosure practices for any vulnerabilities discovered through this research.

---

## Intended Use

**Acceptable uses:**
- Training and evaluating disinformation detection models
- Researching cross-lingual transfer for NLP systems
- Studying the digital language divide and resource inequity
- Developing multilingual AI safety tools
- Academic benchmarking and reproducibility studies

**Unacceptable uses:**
- Generating or distributing disinformation
- Training models to produce misleading content
- Circumventing content moderation systems
- Any purpose that undermines information integrity
- Commercial deployment without appropriate licensing

---

## Fairness Considerations

### Digital Language Divide

A core motivation of BLUFF is addressing the inequity in disinformation detection resources. We explicitly measure and report the performance gap between big-head (20) and long-tail (58) languages to ensure that progress in multilingual AI does not solely benefit already well-resourced languages.

### Representational Fairness

The dataset covers 12 language families, 10+ script types, 4 syntactic word orders, and 12 geographic regions. While comprehensive, coverage is not uniform — this is documented in the DATASHEET and Language Taxonomy to enable informed use.

### Evaluation Fairness

All benchmark tasks use macro-averaged F1 to prevent high-resource languages from dominating aggregate scores. Results are disaggregated by resource category, language family, script type, and syntactic order to surface disparities.

---

## Institutional Review

This research was conducted at Penn State University under the guidance of the College of Information Sciences and Technology. The dataset construction involves publicly available data and LLM-generated synthetic content, and does not involve human subjects research.

---

## Contact for Ethical Concerns

If you identify ethical issues with the BLUFF benchmark, please contact:

- **Jason Lucas** — jsl5710@psu.edu
- **Dongwon Lee** — dongwon@psu.edu
- Report via GitHub Issues: [https://github.com/jsl5710/BLUFF/issues](https://github.com/jsl5710/BLUFF/issues)
